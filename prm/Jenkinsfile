pipeline {
//    triggers {
//        cron('H/30 * * * *')
//    }
    agent any
    environment {
        PLAYBOOK='prm/workload-collocation-agent/workloads/run_workloads.yaml'
        PROMETHEUS='http://100.64.176.12:9090' 
        MESOS='100.64.176.23'
        KUBERNETES='100.64.176.34'
        LLC_BASELINE_SLEEP = 180 
        LLC_COLLECT_SLEEP = 36000
        LLC_CONTENDER_SLEEP = 180
        MBW_BASELINE_SLEEP = 5
        MBW_CONTENDER_SLEEP = 5
        BUILD_COMMIT = "${GIT_COMMIT}"
        EXTRA_ANSIBLE_PARAMS = " "
    }
    options {
        disableConcurrentBuilds()
        timeout(time: 1200, unit: 'MINUTES')
    }
    parameters {
        booleanParam(name: 'BUILD_PEX', defaultValue: true, description: 'Build wca-pex')
        booleanParam(name: 'LLC', defaultValue: true, description: 'Run LLC experiment')
        booleanParam(name: 'BUILD_LLC_MODEL', defaultValue: false, description: 'Build Model For LLC Contention')
        booleanParam(name: 'MB', defaultValue: false, description: 'Run MBW experiment')
    }
    stages {
        stage('Build pex') {
            when { expression { return params.BUILD_PEX } }
            stages {
                    stage("Prepare venv && build pex | Mesos") {
                        agent { label 'mesos' }
                        steps {
                            build_pex()
                            }
                        }
                    stage("Prepare venv && build pex | Kubernetes") {
                        agent { label 'kubernetes' }
                        steps {
                            build_pex()
                            }
                        }
            }
        }
        stage("Prepare aurora cluster") {
            when { expression { return params.MB | params.LLC} }
            agent {label 'mesos'}
            steps {
                sh'''
                mkdir -p ${HOME}/.aurora
                cp ${WORKSPACE}/prm/demo_scenarios/common/aurora-clusters.json  ${HOME}/.aurora/clusters.json
                '''
            }
        }
        stage("Mesos") {
            agent {label 'mesos'}
            environment {
                MESOS_MASTER_HOST = "${MESOS}"
                MESOS_EXPECTED_TASKS = -1
                INVENTORY='prm/demo_scenarios/common/inventory-mesos.yaml'
                MIN_RECALL = -1
                MIN_PRECISION = -1
                LABELS="""{additional_labels: {build_number: "${BUILD_NUMBER}", build_node_name: "${NODE_NAME}", build_commit: "${GIT_COMMIT}", build_scenario: "$BUILD_SCENARIO"}}"""
            }
            steps {
                stage("Run LLC Metrics Collection | Mesos") {
                        when { expression { return params.BUILD_LLC_MODEL } }
                        environment {
                            SCENARIO_INVENTORY='prm/demo_scenarios/complex_llc.0/inventory.yaml'
                            BUILD_SCENARIO = "llc"
                        }
                        steps {
                            llc_metrics_collection()
                        }
                        post {
                            always {
                                clean("LLC", "llc_results.csv")
                            }
                        }
                }
                stage("Run LLC experiment | Mesos") {
                    when { expression { return params.LLC } }
                    environment {
                        BUILD_SCENARIO = "llc"
                        SCENARIO_INVENTORY='prm/demo_scenarios/complex_llc.0/inventory.yaml'
                    }
                    steps {
                        llc_experiment()
                    }
                    post {
                        always {
                            clean("LLC", "llc_results.csv")
                        }
                    }
                }
                stage("Run Memory Bandwidth experiment | Mesos") {
                    when { expression { return params.MB } }
                    environment {
                        BUILD_SCENARIO = "mbw"
                        SCENARIO_INVENTORY='prm/demo_scenarios/complex_mbw.0/inventory.yaml'
                    }
                    steps {
                        memory_bandwidth_experiment()
                    }
                    post {
                        always {
                            clean("MBW", "mbw_results.csv")
                        }
                    }
                }
            }
        }
        stage("Kubernetes") {
            agent {label 'kubernetes'}
            environment {
                KUBERNETES_HOST = "${KUBERNETES}"
                KUBERNETES_EXPECTED_TASKS = -1
                INVENTORY='prm/demo_scenarios/common/inventory-kubernetes.yaml'
                CRT_PATH = "/etc/kubernetes/ssl"
                LABELS="""{additional_labels: {build_number: "${BUILD_NUMBER}", build_node_name: "${NODE_NAME}", build_commit: "${GIT_COMMIT}", build_scenario: "$BUILD_SCENARIO"}}"""
            }
            steps {
                stage("Run LLC Metrics Collection | Kubernetes") {
                    when { expression { return params.BUILD_LLC_MODEL } }
                    environment {
                        BUILD_SCENARIO = "llc"
                        SCENARIO_INVENTORY='prm/demo_scenarios/complex_llc.0/inventory.yaml'
                    }
                    steps {
                        llc_metrics_collection()
                    }
                    post {
                        always {
                            clean("LLC", "llc_results.csv")
                        }
                    }
                }
                stage("Run LLC experiment | Kubernetes") {
                    when { expression { return params.LLC } }
                    environment {
                        BUILD_SCENARIO = "llc"
                        SCENARIO_INVENTORY='prm/demo_scenarios/complex_llc.0/inventory.yaml'
                    }
                    steps {
                        llc_experiment()
                    }
                    post {
                        always {
                            clean("LLC", "llc_results.csv")
                        }
                    }
                }
                stage("Run Memory Bandwidth experiment | Kubernetes") {
                    when { expression { return params.MB } }
                    environment {
                        BUILD_SCENARIO = "mbw"
                        SCENARIO_INVENTORY='prm/demo_scenarios/complex_mbw.0/inventory.yaml'
                    }
                    steps {
                        memory_bandwidth_experiment()
                    }
                    post {
                        always {
                            clean("MBW", "mbw_results.csv")
                        }
                    }
                }
            }
        }
    }
}

def clean(scenario, csv_file) {
    stop_workloads()
    sleep 5
    plot_results(scenario, csv_file)
    stop_wca()
}

def plot_results(scenario, csv_file) {
    echo """Plot ${scenario} results..."""
    plot(csvFileName: "${csv_file}",
         style: 'line',
         csvSeries: [
            [
                displayTableFlag: false,
                exclusionValues: '',
                inclusionFlag: 'OFF',
                file: 'prm/test_results.csv',
                url: ''
            ]
         ],
         group: 'PRM performance v4',
         title: "${scenario} complex scenario",
         numBuilds: '5',)
    echo 'Storing results.'
    junit 'prm/unit_results.xml'
}

def reconfigure_wca() {
    echo 'Reconfigure wca...'
    sh 'cp ${WORKSPACE}/prm/demo_scenarios/common/wca_config.yml ${WORKSPACE}/prm/demo_scenarios/common/wca_config.yml.tmp'
    sh 'sudo cp ${WORKSPACE}/prm/demo_scenarios/common/wca.service /etc/systemd/system/wca.service'
    sh 'sudo systemctl daemon-reload'
    contentReplace(
        configs: [
            fileContentReplaceConfig(
                configs: [
                    fileContentReplaceItemConfig( search: 'BUILD_COMMIT', replace: "${GIT_COMMIT}", matchCount: 0),
                    fileContentReplaceItemConfig( search: 'BUILD_NUMBER', replace: "${BUILD_NUMBER}", matchCount: 0),
                    fileContentReplaceItemConfig( search: 'BUILD_SCENARIO', replace: "${BUILD_SCENARIO}", matchCount: 0)],
                fileEncoding: 'UTF-8',
                filePath: "${WORKSPACE}/prm/demo_scenarios/common/wca_config.yml.tmp")])
    sh'''
    sudo mkdir -p /var/lib/wca/
    sudo mkdir -p /etc/wca
    sudo cp ${WORKSPACE}/prm/demo_scenarios/common/threshold.json /var/lib/wca/
    sudo cp ${WORKSPACE}/prm/demo_scenarios/common/workload.json /var/lib/wca/
    sudo cp ${WORKSPACE}/prm/demo_scenarios/common/wca_config.yml.tmp /etc/wca/wca_config.yml
    sudo cp ${WORKSPACE}/prm/dist/wca-prm.pex /usr/bin/wca.pex
    '''
}

def start_wca() {
    '''
    echo 'Restart wca...'
    sudo systemctl restart wca
    sleep 5
    sh 'sudo systemctl status wca'
    '''
}

def start_workloads(extra_params, tags, sleep_time) {
    dir('prm/workload-collocation-agent/workloads'){
        sh """ansible-playbook  ${extra_params}  -i ${WORKSPACE}/${SCENARIO_INVENTORY} -i ${WORKSPACE}/${INVENTORY} --tags=${tags} -e "${LABELS}" ${WORKSPACE}/${PLAYBOOK}"""
        sleep sleep_time
    }

}

def calculate_precision() {
    dir('prm'){
        echo 'Calculate precision and recall...'
        sh "PYTHONPATH=. pipenv run pytest tests/e2e/test_calculate_accuracy.py --junitxml=unit_results.xml --junit-prefix=${BUILD_SCENARIO} --log-level=debug --log-cli-level=debug -v"
    }
}

def stop_workloads() {
    echo 'Stop all workloads...'
    sh 'ansible-playbook  ${EXTRA_ANSIBLE_PARAMS}  -i ${WORKSPACE}/${INVENTORY} --tags=clean_jobs ${WORKSPACE}/${PLAYBOOK}'
}

def stop_wca() {
    echo 'Stop wca...'
    sh 'sudo systemctl stop wca'
}

def build_pex() {
    dir('prm') {
        sh('make venv')
        sh('make check')
        sh('make package')
        }
}

def llc_metrics_collection() {
    reconfigure_wca()
    start_wca()
    echo 'Start baseline workloads.'
    start_workloads("${EXTRA_ANSIBLE_PARAMS}", 'twemcache_mutilate,redis_rpc_perf,cassandra_stress--cassandra', "${LLC_COLLECT_SLEEP}")
    calculate_precision()
}

def llc_experiment() {
    reconfigure_wca()
    start_wca()
    dir('prm/workload-collocation-agent/workloads') {
        sh 'sed -i s/number_of_rows=100000$/number_of_rows=10000/g ./cassandra_stress/cassandra_stress.aurora'
        sh 'sed -i s/40000/2000/g ./mutilate/mutilate.aurora'
        sh 'sed -i s/-C\\ %d\\;/-C\\ %d\\ -R\\ 2000\\;/g ./mutilate/mutilate.aurora'
    }
    echo 'Start baseline workloads.'
	start_workloads("${EXTRA_ANSIBLE_PARAMS}", 'twemcache_mutilate,redis_rpc_perf,cassandra_stress--cassandra', "${LLC_BASELINE_SLEEP}")
	echo 'Start contender workload.'
	start_workloads("${EXTRA_ANSIBLE_PARAMS}", 'cassandra_stress--stress', "${LLC_CONTENDER_SLEEP}")
    calculate_precision()
}

def memory_bandwidth_experiment() {
    reconfigure_wca()
    start_wca()
    echo 'Start baseline workloads.'
    start_workloads("${EXTRA_ANSIBLE_PARAMS}", 'specjbb,tensorflow_benchmark_prediction,tensorflow_benchmark_train,cassandra_stress', "${MBW_BASELINE_SLEEP}")
    echo 'Start contender workload.'
    start_workloads("${EXTRA_ANSIBLE_PARAMS}", 'tensorflow_benchmark_prediction', "${MBW_CONTENDER_SLEEP}")
    calculate_precision()
}
